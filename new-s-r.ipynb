{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAX9dv_K21p4"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "# Set the folder where your 200 CSV files are located\n",
        "# folder_path = \"/content\"\n",
        "folder_path = r\"C:\\Users\\3ddev\\OneDrive\\Thesis\\Characterization\\New-SnS2-esserc\\SnS2\\SnS2\\D12\" # ðŸ”¹ CHANGE THIS TO YOUR CSV FOLDER\n",
        "# C:\\Users\\3ddev\\OneDrive\\Thesis\\Characterization\\New-SnS2-esserc\\SnS2\\SnS2\\D2\n",
        "# Initialize an empty dictionary for storing data\n",
        "data_dict = {}\n",
        "\n",
        "# Variable to store CH1 Source (only from 1s.csv and 1r.csv)\n",
        "source_column = None\n",
        "\n",
        "# Process each pair of files (1S & 1R, 2S & 2R, ..., 100S & 100R)\n",
        "for i in range(1, 101):\n",
        "    s_filename = os.path.join(folder_path, f\"{i}S.csv\")\n",
        "    r_filename = os.path.join(folder_path, f\"{i}R.csv\")\n",
        "\n",
        "    # Check if both files exist\n",
        "    if not os.path.exists(s_filename) or not os.path.exists(r_filename):\n",
        "        print(f\"Skipping {i}: Missing {s_filename} or {r_filename}\")\n",
        "        continue\n",
        "\n",
        "    # Read CSV files\n",
        "    s_df = pd.read_csv(s_filename)\n",
        "    r_df = pd.read_csv(r_filename)\n",
        "\n",
        "    # Ensure required columns exist\n",
        "    required_cols = {'CH1 Current', 'CH1 Source'}\n",
        "    if not required_cols.issubset(s_df.columns) or not required_cols.issubset(r_df.columns):\n",
        "        print(f\"Skipping {i}: Required columns not found\")\n",
        "        continue\n",
        "\n",
        "    # Store CH1 Current from each file\n",
        "    data_dict[f'Current_{i}'] = list(s_df['CH1 Current']) + list(r_df['CH1 Current'])\n",
        "\n",
        "    # Store CH1 Source **only for 1s and 1r** (append 1r after 1s)\n",
        "    if i == 1:\n",
        "        source_column = list(s_df['CH1 Source']) + list(r_df['CH1 Source'])\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "final_df = pd.DataFrame(dict(CH1_Source=source_column))  # Start with CH1 Source\n",
        "\n",
        "# Add Current_X columns to the DataFrame\n",
        "for key, values in data_dict.items():\n",
        "    max_len = max(len(final_df), len(values))\n",
        "    final_df = final_df.reindex(range(max_len))  # Extend to match longest column\n",
        "    final_df[key] = values + [None] * (max_len - len(values))  # Pad with NaN if needed\n",
        "\n",
        "# Save as CSV\n",
        "final_filename = os.path.join(folder_path, 'final_combined.csv')\n",
        "final_df.to_csv(final_filename, index=False)\n",
        "# files.download(\"/content/final_combined.csv\")\n",
        "print(f\"âœ… Processing complete. File saved at: {final_filename}\")\n"
      ]
    }
  ]
}